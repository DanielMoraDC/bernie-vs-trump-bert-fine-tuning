{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT overview\n",
    "\n",
    "This notebook shows how to feed text data into a pre-trained BERT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import (\n",
    "    Tuple,\n",
    "    List\n",
    ")\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "\n",
    "from transformers import (\n",
    "    BertModel,\n",
    "    BertTokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is a huge list of pre-trained models in https://huggingface.co/models\n",
    "# You can also pre-train yours and upload it!\n",
    "pretrained_model_name = 'bert-base-cased'\n",
    "tokenizer = BertTokenizer.from_pretrained(pretrained_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = 'The black dog is sleeping on the couch'\n",
    "sample_token_ids = tokenizer.encode(sample_text, add_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 1109, 1602, 3676, 1110, 5575, 1113, 1103, 5943, 102]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_token_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we truncate the sentence?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 1109, 1602, 3676, 102]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(sample_text,\n",
    "                 truncation=True,\n",
    "                 max_length=5,\n",
    "                 add_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if the expected sentence length is longer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[101, 1109, 1602, 3676, 1110, 5575, 1113, 1103, 5943, 102, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.encode(sample_text,\n",
    "                 truncation=True,\n",
    "                 max_length=15,\n",
    "                 padding='max_length',\n",
    "                 add_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feeding data into BERT\n",
    "\n",
    "We will visualize what BERT outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first load the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = BertModel.from_pretrained(pretrained_model_name,\n",
    "                                  output_hidden_states=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_tensor = torch.tensor(sample_token_ids).unsqueeze(0).to(device)\n",
    "last_hidden_state, pooled, hidden_states = model(tokens_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get, for each layer, a token-level representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.1536,  0.0562,  0.1367,  ..., -0.0989,  0.3940,  0.1002],\n",
      "         [-0.4726, -0.1651,  0.1575,  ...,  0.6513,  0.1141,  0.5288],\n",
      "         [-0.0889, -0.3289, -0.1701,  ...,  0.6400,  0.1992,  0.5205],\n",
      "         ...,\n",
      "         [-0.1692, -0.4604,  0.2934,  ...,  0.1403,  0.2538,  0.3727],\n",
      "         [ 0.3087, -0.3969, -0.0714,  ..., -0.3647,  0.7529, -0.1209],\n",
      "         [ 0.9193,  0.1145,  0.0871,  ..., -0.0265,  0.4273,  0.0366]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n",
      "tensor([[[ 0.1536,  0.0562,  0.1367,  ..., -0.0989,  0.3940,  0.1002],\n",
      "         [-0.4726, -0.1651,  0.1575,  ...,  0.6513,  0.1141,  0.5288],\n",
      "         [-0.0889, -0.3289, -0.1701,  ...,  0.6400,  0.1992,  0.5205],\n",
      "         ...,\n",
      "         [-0.1692, -0.4604,  0.2934,  ...,  0.1403,  0.2538,  0.3727],\n",
      "         [ 0.3087, -0.3969, -0.0714,  ..., -0.3647,  0.7529, -0.1209],\n",
      "         [ 0.9193,  0.1145,  0.0871,  ..., -0.0265,  0.4273,  0.0366]]],\n",
      "       grad_fn=<NativeLayerNormBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(last_hidden_state)\n",
    "print(hidden_states[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "print(len(hidden_states))  # 12 layers + embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10, 768])\n"
     ]
    }
   ],
   "source": [
    "print(hidden_states[5].shape)  # N x N_tokens # H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.7002,  0.4506,  0.9999, -0.9920,  0.9600,  0.8650,  0.9825, -0.9862,\n",
      "        -0.9753, -0.5934], grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Last layer hidden-state of the first token of the sequence (classification token)\n",
    "# further processed by a Linear layer and a Tanh activation function. \n",
    "print(pooled[0, :10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use different strategies for creating sentence embeddings from token-level embeddings. Some examples:\n",
    "    \n",
    "    - Use average of tokens in the last hidden layer.\n",
    "    - Use average of tokens in the second-to-last hidden layer.\n",
    "    - Use average over tokens for the average of the last 4 layers.\n",
    "    \n",
    "Let's use this last approach for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 768])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def summarize_hidden_states(hidden_states: Tuple, n_last_layers: int = 4) -> torch.Tensor:\n",
    "    layers_avg = torch.mean(\n",
    "        torch.stack(hidden_states[-n_last_layers:]),\n",
    "        dim=0\n",
    "    )\n",
    "    tokens_avg = torch.mean(layers_avg, dim=1)\n",
    "    return tokens_avg\n",
    "\n",
    "summarize_hidden_states(hidden_states).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sentence_embedding(token_ids: List[int]) -> np.ndarray:\n",
    "    with torch.no_grad():\n",
    "        tokens_tensor = torch.tensor(token_ids).unsqueeze(0).to(device)\n",
    "        _, _, hidden_states = model(tokens_tensor)\n",
    "        embedding_tensor = summarize_hidden_states(hidden_states)\n",
    "        return embedding_tensor.cpu().numpy().squeeze(0)\n",
    "\n",
    "sentence_embedding(sample_token_ids).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this embedding we can perform several tasks such as classification or clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence embedding as feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.    , 313.4347, 291.3957, 288.2623],\n",
       "       [313.4347,   0.    , 288.2033, 281.8941],\n",
       "       [291.3957, 288.2033,   0.    , 283.4817],\n",
       "       [288.2623, 281.8941, 283.4817,   0.    ]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = [\n",
    "    'there is a dog sleeping on the garden',\n",
    "    'there was a puppy resting at the back of the house',\n",
    "    'around 85% of households in the UK have a dog in it',\n",
    "    'european prime ministers agreed on a plan to tackle the coronavirus crisis'\n",
    "]\n",
    "\n",
    "embeddings = np.stack([\n",
    "    sentence_embedding(tokenizer.encode(sentence, add_special_tokens=True))\n",
    "    for sentence in sentences\n",
    "])\n",
    "\n",
    "similarities = np.dot(embeddings, embeddings.T)\n",
    "np.fill_diagonal(similarities, 0)\n",
    "similarities"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
